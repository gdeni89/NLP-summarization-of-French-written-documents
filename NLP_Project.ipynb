{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gdeni89/NLP-summarization-of-French-written-documents/blob/main/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Project"
      ],
      "metadata": {
        "id": "-Qb1qquwYRNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proposal : \n",
        "\n",
        "<blockquote>\n",
        "\n",
        "Instructions :  \n",
        "\n",
        "Provide details on your project . It should be a paragraph describing your project, what datasets you will be using, what modelling techniques and what evaluation you will be doing\n",
        "</blockquote>"
      ],
      "metadata": {
        "id": "cqv8KC3zYqRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Possible Datasets in French :** \n",
        " \n",
        "    * [OrangeSum](https://github.com/Tixierae/OrangeSum) : dataset that was proposed for text summarization but in **French** (which is less studied in litterature than English) : articles with summaries, already grouped in categories (political, environment, ...) so we will be able to easily compare the perf of our model on different \"subjects\"\n",
        "\n",
        "    \\+ this dataset was proposed together with \"BARThez\", a seq2seq model proposed specifically for French and which is said to be more efficient than BERT-based models for French, above all for generative tasks ([associated article](https://arxiv.org/pdf/2010.12321.pdf))\n",
        "\n",
        "  * [CASS](https://github.com/euranova/CASS-dataset) (summaries of \"procès en cours de cassation\", maybe less interesting and diverse than news articles)\n",
        "\n",
        "  * [MLSum](https://huggingface.co/datasets/mlsum) & [XL-Sum](https://huggingface.co/datasets/csebuetnlp/xlsum) : datasets proposed by HuggingFace and composed of articles with abstracts on different languages, I guess we can concentrate on French subcorpus. It was originally proposed for multilingual text summarization ([see article for XLSum](https://arxiv.org/pdf/2106.13822v1.pdf) or [article for MLSum](https://arxiv.org/pdf/2004.14900v1.pdf))\n",
        "\n",
        "  * [WikiLingual](https://paperswithcode.com/dataset/wikilingua) : article and summary pairs of Wikipedia articles in different languages\n",
        "\n"
      ],
      "metadata": {
        "id": "tJx2dp89Y9wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Possible Language models for French :**\n",
        "\n",
        "  - [CamemBERT](https://camembert-model.fr/)\n",
        "  - [FlauBERT](https://github.com/getalp/Flaubert)\n",
        "  - [Deepfrench](https://github.com/tchambon/deepfrench) : pre-trained on Wikipedia corpuses, principally proposed for classification tasks\n",
        "  - BARThez "
      ],
      "metadata": {
        "id": "T-we06PDMNMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description of the task and approach(es)** :\n",
        "\n",
        "The idea of text summarization is to produce a summary of a text (or corpus of text if we want to extend it). There is two main possible approches :\n",
        "\n",
        "**1. Extractive Approach :**\n",
        "\n",
        "The first (maybe simplest) approach is to form a summary by selecting some sentences of the text (without modifying it at all). To do so, we need to find a way to \"score\" the sentences of the document to extract only the most revelant ones. \n",
        "\n",
        "An example of algorithm that we can try to implement is the TextRank algorithm, which is unsupervised and with few DL. The idea is to compute a similarity matrix between the sentences of our document, which can be done by computing similarities between embeddings of the sentences (with Seq2Vec for instance).\n",
        "\n",
        "[Example of tuto really well detailed for Extractive Approach](https://www.analyticsvidhya.com/blog/2018/11/introduction-text-summarization-textrank-python//)\n",
        "\n",
        "\n",
        "**2. Abstractive Approach :**\n",
        "\n",
        "A more advanced approach is to generate the summary, that is to say to produce a summary with sentences that we have generated and do not exist in the document to summarize. \n",
        "\n",
        "For this task, we may use DL, with models such as Transformers with Attention Mechanism (or Encoder-Decoder to start but it's more limited and should lead to worse perf than Transformers).\n",
        "\n",
        "[Example of tuto really well detailed for Abstractive Approach](https:https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python///)\n",
        "\n"
      ],
      "metadata": {
        "id": "7mUBzP7Ua3fH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**⇒ Proposal :**\n",
        "\n",
        "Our project will focus on the text summarization task applied to the summarization of French written documents. (We will not cover multi-lingual models and summarization of corpus of documents, which are possible extensions of this task).\n",
        "\n",
        "Formally, our goal will be to implement and compare different approaches to produce a summary from a given text. As a \"baseline\", we will implement the more \"naive\" method to adress this task, which is called \"Extractive Approach\" and is unsupervised : the idea is to choose some embeddings for the sentences of a text, and compute a similarity matrix to form a summary by extracting the most revelant sentences of our text. Then, we will study the more advanced \"Abstractive approach\", where the idea is to leverage deep learning models (Encoder-Decoder or Attention Mechanism of Transformers), to build supervised generative models that will generate new sentences to create a summary.\n",
        "\n",
        "Concerning the datasets, we would like to train our models on news articles with their summaries in French, which can be found in datasets such as MLSum, XLSum or OrangeSum. As we are studying French written texts, we will use and compare some language models specific to French, such as FlauBERT, CamemBERT, DeepFrench or BARTHez. Moreover, to evaluate the performance of our generated summaries, we will use the ROUGE metric, which was specifically designed for this task and used in the litterature. We may also do some experiments by challenging our models on different type of texts, such as the ones available in WikiLingual or CASS."
      ],
      "metadata": {
        "id": "pYt5YcxJ5c7B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6Mbppf0YOXY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}